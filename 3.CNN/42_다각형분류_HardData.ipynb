{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"42_다각형분류_HardData.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMhpve6w4ZF/cYatZDoHgrP"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-Klk_IW7c7Tr"},"source":["# 원, 삼각형, 사각형 구분하기\r\n","김태영의 컨볼루션신경망모델 만들어보기 [참조]\r\n","https://tykimos.github.io/2017/03/08/CNN_Getting_Started/\r\n","## 2. 어려운 테스트 문제를 기존 CNN 모델로 푸는 경우"]},{"cell_type":"code","metadata":{"id":"xZQeZqH4iwJj","executionInfo":{"status":"ok","timestamp":1613524335568,"user_tz":-540,"elapsed":749,"user":{"displayName":"고녹녹","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UXxlJ9dgM27f3BTzP91L9Si-FkCyJfTt58oI=s64","userId":"12157940257772241278"}}},"source":["!unzip -qq hard_handwriting_shape.zip -d hard_handwriting_shape"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"XldcCCm9c21w","executionInfo":{"status":"ok","timestamp":1613524348509,"user_tz":-540,"elapsed":749,"user":{"displayName":"고녹녹","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UXxlJ9dgM27f3BTzP91L9Si-FkCyJfTt58oI=s64","userId":"12157940257772241278"}}},"source":["import numpy as np\r\n","import tensorflow as tf\r\n","from tensorflow import keras\r\n","from tensorflow.keras.models import Sequential\r\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\r\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n","# seed 값 설정\r\n","seed = 2020\r\n","np.random.seed(seed)\r\n","tf.random.set_seed(seed)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"16StwGdndsZN"},"source":["### 데이터셋 생성하기"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QuWfzy4Xdsdj","executionInfo":{"status":"ok","timestamp":1613524386995,"user_tz":-540,"elapsed":725,"user":{"displayName":"고녹녹","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UXxlJ9dgM27f3BTzP91L9Si-FkCyJfTt58oI=s64","userId":"12157940257772241278"}},"outputId":"17901119-396b-447a-9279-e7706ce4e976"},"source":["train_datagen = ImageDataGenerator(rescale=1./255) #0~1사이의값으로 정규화\r\n","#트레인셋을 넘파이 어레이로 만들기\r\n","train_generator = train_datagen.flow_from_directory(\r\n","    'hard_handwriting_shape/train',\r\n","    target_size=(24,24),\r\n","    batch_size=3,\r\n","    class_mode='categorical'\r\n",")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Found 45 images belonging to 3 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Forq6-t1dsf8","executionInfo":{"status":"ok","timestamp":1613524395468,"user_tz":-540,"elapsed":741,"user":{"displayName":"고녹녹","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UXxlJ9dgM27f3BTzP91L9Si-FkCyJfTt58oI=s64","userId":"12157940257772241278"}},"outputId":"98411fd6-2d37-447a-b308-04a882a7a608"},"source":["!ls hard_handwriting_shape/train\r\n","#파일3가지를 만들어진것 확인\r\n","#circle\trectangle  triangle"],"execution_count":7,"outputs":[{"output_type":"stream","text":["circle\trectangle  triangle\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gaJHK5Y5dsiL","executionInfo":{"status":"ok","timestamp":1613524420410,"user_tz":-540,"elapsed":746,"user":{"displayName":"고녹녹","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UXxlJ9dgM27f3BTzP91L9Si-FkCyJfTt58oI=s64","userId":"12157940257772241278"}},"outputId":"0e34b53b-9c5b-4914-80fd-76d50e766f1f"},"source":["test_datagen = ImageDataGenerator(rescale=1./255) #0~1사이의값으로 정규화\r\n","#테스트셋을 넘파이 어레이로 만들기\r\n","test_generator = test_datagen.flow_from_directory(\r\n","    'hard_handwriting_shape/test',\r\n","    target_size=(24,24),\r\n","    batch_size=3,\r\n","    class_mode='categorical'\r\n",")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Found 15 images belonging to 3 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MzIAMVAGdsku","executionInfo":{"status":"ok","timestamp":1613524444904,"user_tz":-540,"elapsed":745,"user":{"displayName":"고녹녹","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UXxlJ9dgM27f3BTzP91L9Si-FkCyJfTt58oI=s64","userId":"12157940257772241278"}},"outputId":"16660dd3-fe9a-4728-8cab-9026fb05beca"},"source":["train_generator.labels"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"947-biAadsnV","executionInfo":{"status":"ok","timestamp":1613524447990,"user_tz":-540,"elapsed":765,"user":{"displayName":"고녹녹","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UXxlJ9dgM27f3BTzP91L9Si-FkCyJfTt58oI=s64","userId":"12157940257772241278"}},"outputId":"07480860-2ab5-4511-ecf5-bebca5bbce77"},"source":["train_generator.filenames[0]"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'circle/circle001.png'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"sb4Zbrvgdspl"},"source":["### 모델 정의/설정/학습"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JOCicg1AdssG","executionInfo":{"status":"ok","timestamp":1613524461740,"user_tz":-540,"elapsed":1053,"user":{"displayName":"고녹녹","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UXxlJ9dgM27f3BTzP91L9Si-FkCyJfTt58oI=s64","userId":"12157940257772241278"}},"outputId":"6b50618b-11b6-4824-a0bf-f948f6c2df53"},"source":["model = Sequential()\r\n","model.add(Conv2D(32, kernel_size=(3, 3),\r\n","                 activation='relu', input_shape=(24,24,3)))\r\n","model.add(Conv2D(64, (3, 3), activation='relu'))\r\n","model.add(MaxPooling2D(pool_size=(2, 2)))\r\n","model.add(Flatten())\r\n","model.add(Dense(128, activation='relu'))\r\n","model.add(Dense(3, activation='softmax'))\r\n","model.summary()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 22, 22, 32)        896       \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 20, 20, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 10, 10, 64)        0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 6400)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               819328    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 3)                 387       \n","=================================================================\n","Total params: 839,107\n","Trainable params: 839,107\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BHyYhyzSdsus","executionInfo":{"status":"ok","timestamp":1613524464768,"user_tz":-540,"elapsed":737,"user":{"displayName":"고녹녹","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UXxlJ9dgM27f3BTzP91L9Si-FkCyJfTt58oI=s64","userId":"12157940257772241278"}}},"source":["model.compile(loss='categorical_crossentropy',\r\n","              optimizer='adam', metrics=['accuracy'])"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j9PTB5DJdsxU"},"source":["#### 모델 학습시키기\r\n","-첫번째 인자 : 훈련데이터셋을 제공할 제네레이터를 지정. 본 예제에서는 앞서 생성한 train_generator으로 지정.  \r\n","-steps_per_epoch : 한 epoch에 사용한 스텝 수를 지정. 총 45개의 훈련 샘플이 있고 배치사이즈가 3이므로 15 스텝으로 지정.  \r\n","-epochs : 전체 훈련 데이터셋에 대해 학습 반복 횟수를 지정. 50번을 반복적으로 학습.  \r\n","-validation_data : 검증데이터셋을 제공할 제네레이터를 지정. 본 예제에서는 앞서 생성한 test_generator으로 지정.  \r\n","-validation_steps : 한 epoch 종료 시 마다 검증할 때 사용되는 검증 스텝 수를 지정. 총 15개의 검증 샘플이 있고 배치사이즈가 3이므로 5 스텝으로 지정."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XpVEYxrfgwuj","executionInfo":{"status":"ok","timestamp":1613524545611,"user_tz":-540,"elapsed":76083,"user":{"displayName":"고녹녹","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UXxlJ9dgM27f3BTzP91L9Si-FkCyJfTt58oI=s64","userId":"12157940257772241278"}},"outputId":"d192016e-c0e2-4d78-bae5-1090aef9fbb1"},"source":["model.fit_generator( # 기존에알고있던것에서 _generator추가됨\r\n","        train_generator,\r\n","        steps_per_epoch=15,\r\n","        epochs=200,\r\n","        validation_data=test_generator,\r\n","        validation_steps=5)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/200\n","15/15 [==============================] - 1s 37ms/step - loss: 1.3894 - accuracy: 0.4825 - val_loss: 1.1747 - val_accuracy: 0.3333\n","Epoch 2/200\n","15/15 [==============================] - 0s 22ms/step - loss: 0.5877 - accuracy: 0.8686 - val_loss: 2.2713 - val_accuracy: 0.3333\n","Epoch 3/200\n","15/15 [==============================] - 0s 23ms/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 3.8655 - val_accuracy: 0.3333\n","Epoch 4/200\n","15/15 [==============================] - 0s 22ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 4.6669 - val_accuracy: 0.3333\n","Epoch 5/200\n","15/15 [==============================] - 0s 22ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.9597 - val_accuracy: 0.3333\n","Epoch 6/200\n","15/15 [==============================] - 0s 24ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.9170 - val_accuracy: 0.3333\n","Epoch 7/200\n","15/15 [==============================] - 0s 22ms/step - loss: 4.3962e-04 - accuracy: 1.0000 - val_loss: 5.0794 - val_accuracy: 0.3333\n","Epoch 8/200\n","15/15 [==============================] - 0s 22ms/step - loss: 1.9064e-04 - accuracy: 1.0000 - val_loss: 5.1816 - val_accuracy: 0.3333\n","Epoch 9/200\n","15/15 [==============================] - 0s 24ms/step - loss: 2.1580e-04 - accuracy: 1.0000 - val_loss: 5.2323 - val_accuracy: 0.3333\n","Epoch 10/200\n","15/15 [==============================] - 0s 22ms/step - loss: 1.4912e-04 - accuracy: 1.0000 - val_loss: 5.2607 - val_accuracy: 0.3333\n","Epoch 11/200\n","15/15 [==============================] - 0s 22ms/step - loss: 1.6929e-04 - accuracy: 1.0000 - val_loss: 5.2920 - val_accuracy: 0.3333\n","Epoch 12/200\n","15/15 [==============================] - 0s 22ms/step - loss: 1.3196e-04 - accuracy: 1.0000 - val_loss: 5.3400 - val_accuracy: 0.3333\n","Epoch 13/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.2055e-04 - accuracy: 1.0000 - val_loss: 5.3794 - val_accuracy: 0.3333\n","Epoch 14/200\n","15/15 [==============================] - 0s 22ms/step - loss: 1.1493e-04 - accuracy: 1.0000 - val_loss: 5.3959 - val_accuracy: 0.3333\n","Epoch 15/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.4580e-04 - accuracy: 1.0000 - val_loss: 5.4275 - val_accuracy: 0.3333\n","Epoch 16/200\n","15/15 [==============================] - 0s 22ms/step - loss: 1.2263e-04 - accuracy: 1.0000 - val_loss: 5.4575 - val_accuracy: 0.3333\n","Epoch 17/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.0723e-04 - accuracy: 1.0000 - val_loss: 5.5012 - val_accuracy: 0.3333\n","Epoch 18/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.0648e-04 - accuracy: 1.0000 - val_loss: 5.5294 - val_accuracy: 0.3333\n","Epoch 19/200\n","15/15 [==============================] - 0s 23ms/step - loss: 6.7300e-05 - accuracy: 1.0000 - val_loss: 5.5503 - val_accuracy: 0.3333\n","Epoch 20/200\n","15/15 [==============================] - 0s 23ms/step - loss: 9.0893e-05 - accuracy: 1.0000 - val_loss: 5.5713 - val_accuracy: 0.3333\n","Epoch 21/200\n","15/15 [==============================] - 0s 23ms/step - loss: 9.4560e-05 - accuracy: 1.0000 - val_loss: 5.6045 - val_accuracy: 0.3333\n","Epoch 22/200\n","15/15 [==============================] - 0s 23ms/step - loss: 6.6337e-05 - accuracy: 1.0000 - val_loss: 5.6257 - val_accuracy: 0.3333\n","Epoch 23/200\n","15/15 [==============================] - 0s 23ms/step - loss: 5.3402e-05 - accuracy: 1.0000 - val_loss: 5.6499 - val_accuracy: 0.3333\n","Epoch 24/200\n","15/15 [==============================] - 0s 24ms/step - loss: 4.7099e-05 - accuracy: 1.0000 - val_loss: 5.6746 - val_accuracy: 0.3333\n","Epoch 25/200\n","15/15 [==============================] - 0s 23ms/step - loss: 4.8727e-05 - accuracy: 1.0000 - val_loss: 5.6816 - val_accuracy: 0.3333\n","Epoch 26/200\n","15/15 [==============================] - 0s 23ms/step - loss: 4.5665e-05 - accuracy: 1.0000 - val_loss: 5.6984 - val_accuracy: 0.3333\n","Epoch 27/200\n","15/15 [==============================] - 0s 23ms/step - loss: 4.4586e-05 - accuracy: 1.0000 - val_loss: 5.7294 - val_accuracy: 0.3333\n","Epoch 28/200\n","15/15 [==============================] - 0s 31ms/step - loss: 3.3749e-05 - accuracy: 1.0000 - val_loss: 5.7525 - val_accuracy: 0.3333\n","Epoch 29/200\n","15/15 [==============================] - 0s 23ms/step - loss: 2.2955e-05 - accuracy: 1.0000 - val_loss: 5.7995 - val_accuracy: 0.3333\n","Epoch 30/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.4820e-05 - accuracy: 1.0000 - val_loss: 5.8167 - val_accuracy: 0.3333\n","Epoch 31/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.2926e-05 - accuracy: 1.0000 - val_loss: 5.8421 - val_accuracy: 0.3333\n","Epoch 32/200\n","15/15 [==============================] - 0s 23ms/step - loss: 9.5566e-06 - accuracy: 1.0000 - val_loss: 5.8901 - val_accuracy: 0.3333\n","Epoch 33/200\n","15/15 [==============================] - 0s 24ms/step - loss: 9.5675e-06 - accuracy: 1.0000 - val_loss: 5.9352 - val_accuracy: 0.3333\n","Epoch 34/200\n","15/15 [==============================] - 0s 24ms/step - loss: 5.4869e-06 - accuracy: 1.0000 - val_loss: 5.9117 - val_accuracy: 0.3333\n","Epoch 35/200\n","15/15 [==============================] - 0s 24ms/step - loss: 5.5110e-06 - accuracy: 1.0000 - val_loss: 5.9697 - val_accuracy: 0.3333\n","Epoch 36/200\n","15/15 [==============================] - 0s 22ms/step - loss: 4.1428e-06 - accuracy: 1.0000 - val_loss: 5.9874 - val_accuracy: 0.3333\n","Epoch 37/200\n","15/15 [==============================] - 0s 24ms/step - loss: 3.6226e-06 - accuracy: 1.0000 - val_loss: 6.0306 - val_accuracy: 0.3333\n","Epoch 38/200\n","15/15 [==============================] - 0s 22ms/step - loss: 3.3181e-06 - accuracy: 1.0000 - val_loss: 6.0559 - val_accuracy: 0.3333\n","Epoch 39/200\n","15/15 [==============================] - 0s 22ms/step - loss: 4.2078e-06 - accuracy: 1.0000 - val_loss: 6.0778 - val_accuracy: 0.3333\n","Epoch 40/200\n","15/15 [==============================] - 0s 23ms/step - loss: 2.6971e-06 - accuracy: 1.0000 - val_loss: 6.1166 - val_accuracy: 0.3333\n","Epoch 41/200\n","15/15 [==============================] - 0s 22ms/step - loss: 3.1985e-06 - accuracy: 1.0000 - val_loss: 6.1172 - val_accuracy: 0.3333\n","Epoch 42/200\n","15/15 [==============================] - 0s 23ms/step - loss: 2.1459e-06 - accuracy: 1.0000 - val_loss: 6.1418 - val_accuracy: 0.3333\n","Epoch 43/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.7165e-06 - accuracy: 1.0000 - val_loss: 6.1652 - val_accuracy: 0.3333\n","Epoch 44/200\n","15/15 [==============================] - 0s 23ms/step - loss: 2.1348e-06 - accuracy: 1.0000 - val_loss: 6.1813 - val_accuracy: 0.3333\n","Epoch 45/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.6171e-06 - accuracy: 1.0000 - val_loss: 6.2024 - val_accuracy: 0.3333\n","Epoch 46/200\n","15/15 [==============================] - 0s 22ms/step - loss: 1.8956e-06 - accuracy: 1.0000 - val_loss: 6.2010 - val_accuracy: 0.3333\n","Epoch 47/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.4675e-06 - accuracy: 1.0000 - val_loss: 6.2351 - val_accuracy: 0.3333\n","Epoch 48/200\n","15/15 [==============================] - 0s 22ms/step - loss: 1.6208e-06 - accuracy: 1.0000 - val_loss: 6.2486 - val_accuracy: 0.3333\n","Epoch 49/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.4965e-06 - accuracy: 1.0000 - val_loss: 6.2691 - val_accuracy: 0.3333\n","Epoch 50/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.2279e-06 - accuracy: 1.0000 - val_loss: 6.2714 - val_accuracy: 0.3333\n","Epoch 51/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.2104e-06 - accuracy: 1.0000 - val_loss: 6.2852 - val_accuracy: 0.3333\n","Epoch 52/200\n","15/15 [==============================] - 0s 22ms/step - loss: 9.6669e-07 - accuracy: 1.0000 - val_loss: 6.3046 - val_accuracy: 0.3333\n","Epoch 53/200\n","15/15 [==============================] - 0s 23ms/step - loss: 9.0698e-07 - accuracy: 1.0000 - val_loss: 6.3148 - val_accuracy: 0.3333\n","Epoch 54/200\n","15/15 [==============================] - 0s 23ms/step - loss: 6.5228e-07 - accuracy: 1.0000 - val_loss: 6.3233 - val_accuracy: 0.3333\n","Epoch 55/200\n","15/15 [==============================] - 0s 22ms/step - loss: 9.9010e-07 - accuracy: 1.0000 - val_loss: 6.3327 - val_accuracy: 0.3333\n","Epoch 56/200\n","15/15 [==============================] - 0s 22ms/step - loss: 7.6048e-07 - accuracy: 1.0000 - val_loss: 6.3511 - val_accuracy: 0.3333\n","Epoch 57/200\n","15/15 [==============================] - 0s 22ms/step - loss: 8.7966e-07 - accuracy: 1.0000 - val_loss: 6.3548 - val_accuracy: 0.3333\n","Epoch 58/200\n","15/15 [==============================] - 0s 24ms/step - loss: 8.3872e-07 - accuracy: 1.0000 - val_loss: 6.3633 - val_accuracy: 0.3333\n","Epoch 59/200\n","15/15 [==============================] - 0s 24ms/step - loss: 6.9842e-07 - accuracy: 1.0000 - val_loss: 6.3732 - val_accuracy: 0.3333\n","Epoch 60/200\n","15/15 [==============================] - 0s 22ms/step - loss: 5.5978e-07 - accuracy: 1.0000 - val_loss: 6.3826 - val_accuracy: 0.3333\n","Epoch 61/200\n","15/15 [==============================] - 0s 23ms/step - loss: 4.4923e-07 - accuracy: 1.0000 - val_loss: 6.4035 - val_accuracy: 0.3333\n","Epoch 62/200\n","15/15 [==============================] - 0s 23ms/step - loss: 6.1827e-07 - accuracy: 1.0000 - val_loss: 6.4144 - val_accuracy: 0.3333\n","Epoch 63/200\n","15/15 [==============================] - 0s 23ms/step - loss: 4.9842e-07 - accuracy: 1.0000 - val_loss: 6.4105 - val_accuracy: 0.3333\n","Epoch 64/200\n","15/15 [==============================] - 0s 22ms/step - loss: 6.6288e-07 - accuracy: 1.0000 - val_loss: 6.4255 - val_accuracy: 0.3333\n","Epoch 65/200\n","15/15 [==============================] - 0s 22ms/step - loss: 5.1063e-07 - accuracy: 1.0000 - val_loss: 6.4324 - val_accuracy: 0.3333\n","Epoch 66/200\n","15/15 [==============================] - 0s 22ms/step - loss: 4.4942e-07 - accuracy: 1.0000 - val_loss: 6.4399 - val_accuracy: 0.3333\n","Epoch 67/200\n","15/15 [==============================] - 0s 23ms/step - loss: 5.7246e-07 - accuracy: 1.0000 - val_loss: 6.4394 - val_accuracy: 0.3333\n","Epoch 68/200\n","15/15 [==============================] - 0s 23ms/step - loss: 4.9395e-07 - accuracy: 1.0000 - val_loss: 6.4498 - val_accuracy: 0.3333\n","Epoch 69/200\n","15/15 [==============================] - 0s 23ms/step - loss: 4.5576e-07 - accuracy: 1.0000 - val_loss: 6.4619 - val_accuracy: 0.3333\n","Epoch 70/200\n","15/15 [==============================] - 0s 24ms/step - loss: 4.6762e-07 - accuracy: 1.0000 - val_loss: 6.4696 - val_accuracy: 0.3333\n","Epoch 71/200\n","15/15 [==============================] - 0s 24ms/step - loss: 4.5292e-07 - accuracy: 1.0000 - val_loss: 6.4830 - val_accuracy: 0.3333\n","Epoch 72/200\n","15/15 [==============================] - 0s 23ms/step - loss: 3.4585e-07 - accuracy: 1.0000 - val_loss: 6.4831 - val_accuracy: 0.3333\n","Epoch 73/200\n","15/15 [==============================] - 0s 25ms/step - loss: 2.8674e-07 - accuracy: 1.0000 - val_loss: 6.4895 - val_accuracy: 0.3333\n","Epoch 74/200\n","15/15 [==============================] - 0s 23ms/step - loss: 3.4728e-07 - accuracy: 1.0000 - val_loss: 6.4927 - val_accuracy: 0.3333\n","Epoch 75/200\n","15/15 [==============================] - 0s 23ms/step - loss: 4.0667e-07 - accuracy: 1.0000 - val_loss: 6.5022 - val_accuracy: 0.3333\n","Epoch 76/200\n","15/15 [==============================] - 0s 24ms/step - loss: 3.1552e-07 - accuracy: 1.0000 - val_loss: 6.5096 - val_accuracy: 0.3333\n","Epoch 77/200\n","15/15 [==============================] - 0s 23ms/step - loss: 4.1673e-07 - accuracy: 1.0000 - val_loss: 6.5151 - val_accuracy: 0.3333\n","Epoch 78/200\n","15/15 [==============================] - 0s 23ms/step - loss: 3.6064e-07 - accuracy: 1.0000 - val_loss: 6.5324 - val_accuracy: 0.3333\n","Epoch 79/200\n","15/15 [==============================] - 0s 22ms/step - loss: 3.1978e-07 - accuracy: 1.0000 - val_loss: 6.5363 - val_accuracy: 0.3333\n","Epoch 80/200\n","15/15 [==============================] - 0s 32ms/step - loss: 2.9699e-07 - accuracy: 1.0000 - val_loss: 6.5448 - val_accuracy: 0.3333\n","Epoch 81/200\n","15/15 [==============================] - 0s 24ms/step - loss: 3.1546e-07 - accuracy: 1.0000 - val_loss: 6.5501 - val_accuracy: 0.3333\n","Epoch 82/200\n","15/15 [==============================] - 0s 22ms/step - loss: 2.2757e-07 - accuracy: 1.0000 - val_loss: 6.5627 - val_accuracy: 0.3333\n","Epoch 83/200\n","15/15 [==============================] - 0s 22ms/step - loss: 3.0225e-07 - accuracy: 1.0000 - val_loss: 6.5700 - val_accuracy: 0.3333\n","Epoch 84/200\n","15/15 [==============================] - 0s 23ms/step - loss: 2.2368e-07 - accuracy: 1.0000 - val_loss: 6.5799 - val_accuracy: 0.3333\n","Epoch 85/200\n","15/15 [==============================] - 0s 23ms/step - loss: 2.3979e-07 - accuracy: 1.0000 - val_loss: 6.5884 - val_accuracy: 0.3333\n","Epoch 86/200\n","15/15 [==============================] - 0s 23ms/step - loss: 2.2891e-07 - accuracy: 1.0000 - val_loss: 6.6018 - val_accuracy: 0.3333\n","Epoch 87/200\n","15/15 [==============================] - 0s 22ms/step - loss: 1.9584e-07 - accuracy: 1.0000 - val_loss: 6.6016 - val_accuracy: 0.3333\n","Epoch 88/200\n","15/15 [==============================] - 0s 22ms/step - loss: 2.1985e-07 - accuracy: 1.0000 - val_loss: 6.6124 - val_accuracy: 0.3333\n","Epoch 89/200\n","15/15 [==============================] - 0s 24ms/step - loss: 2.2318e-07 - accuracy: 1.0000 - val_loss: 6.6173 - val_accuracy: 0.3333\n","Epoch 90/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.5628e-07 - accuracy: 1.0000 - val_loss: 6.6229 - val_accuracy: 0.3333\n","Epoch 91/200\n","15/15 [==============================] - 0s 25ms/step - loss: 2.2416e-07 - accuracy: 1.0000 - val_loss: 6.6264 - val_accuracy: 0.3333\n","Epoch 92/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.6872e-07 - accuracy: 1.0000 - val_loss: 6.6299 - val_accuracy: 0.3333\n","Epoch 93/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.6893e-07 - accuracy: 1.0000 - val_loss: 6.6318 - val_accuracy: 0.3333\n","Epoch 94/200\n","15/15 [==============================] - 0s 22ms/step - loss: 2.0399e-07 - accuracy: 1.0000 - val_loss: 6.6398 - val_accuracy: 0.3333\n","Epoch 95/200\n","15/15 [==============================] - 0s 24ms/step - loss: 2.1311e-07 - accuracy: 1.0000 - val_loss: 6.6403 - val_accuracy: 0.3333\n","Epoch 96/200\n","15/15 [==============================] - 0s 23ms/step - loss: 2.5019e-07 - accuracy: 1.0000 - val_loss: 6.6407 - val_accuracy: 0.3333\n","Epoch 97/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.7936e-07 - accuracy: 1.0000 - val_loss: 6.6464 - val_accuracy: 0.3333\n","Epoch 98/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.3730e-07 - accuracy: 1.0000 - val_loss: 6.6457 - val_accuracy: 0.3333\n","Epoch 99/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.7910e-07 - accuracy: 1.0000 - val_loss: 6.6471 - val_accuracy: 0.3333\n","Epoch 100/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.4571e-07 - accuracy: 1.0000 - val_loss: 6.6460 - val_accuracy: 0.3333\n","Epoch 101/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.5459e-07 - accuracy: 1.0000 - val_loss: 6.6491 - val_accuracy: 0.3333\n","Epoch 102/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.3978e-07 - accuracy: 1.0000 - val_loss: 6.6502 - val_accuracy: 0.3333\n","Epoch 103/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.1573e-07 - accuracy: 1.0000 - val_loss: 6.6504 - val_accuracy: 0.3333\n","Epoch 104/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.4687e-07 - accuracy: 1.0000 - val_loss: 6.6543 - val_accuracy: 0.3333\n","Epoch 105/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.3487e-07 - accuracy: 1.0000 - val_loss: 6.6558 - val_accuracy: 0.3333\n","Epoch 106/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.1998e-07 - accuracy: 1.0000 - val_loss: 6.6595 - val_accuracy: 0.3333\n","Epoch 107/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.2018e-07 - accuracy: 1.0000 - val_loss: 6.6636 - val_accuracy: 0.3333\n","Epoch 108/200\n","15/15 [==============================] - 0s 22ms/step - loss: 9.8287e-08 - accuracy: 1.0000 - val_loss: 6.6648 - val_accuracy: 0.3333\n","Epoch 109/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.3694e-07 - accuracy: 1.0000 - val_loss: 6.6654 - val_accuracy: 0.3333\n","Epoch 110/200\n","15/15 [==============================] - 0s 22ms/step - loss: 1.6752e-07 - accuracy: 1.0000 - val_loss: 6.6670 - val_accuracy: 0.3333\n","Epoch 111/200\n","15/15 [==============================] - 0s 24ms/step - loss: 1.2929e-07 - accuracy: 1.0000 - val_loss: 6.6713 - val_accuracy: 0.3333\n","Epoch 112/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.3878e-07 - accuracy: 1.0000 - val_loss: 6.6739 - val_accuracy: 0.3333\n","Epoch 113/200\n","15/15 [==============================] - 0s 24ms/step - loss: 1.6633e-07 - accuracy: 1.0000 - val_loss: 6.6712 - val_accuracy: 0.3333\n","Epoch 114/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.2205e-07 - accuracy: 1.0000 - val_loss: 6.6756 - val_accuracy: 0.3333\n","Epoch 115/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.0788e-07 - accuracy: 1.0000 - val_loss: 6.6815 - val_accuracy: 0.3333\n","Epoch 116/200\n","15/15 [==============================] - 0s 24ms/step - loss: 8.8968e-08 - accuracy: 1.0000 - val_loss: 6.6825 - val_accuracy: 0.3333\n","Epoch 117/200\n","15/15 [==============================] - 0s 23ms/step - loss: 8.9405e-08 - accuracy: 1.0000 - val_loss: 6.6854 - val_accuracy: 0.3333\n","Epoch 118/200\n","15/15 [==============================] - 0s 24ms/step - loss: 9.7328e-08 - accuracy: 1.0000 - val_loss: 6.6905 - val_accuracy: 0.3333\n","Epoch 119/200\n","15/15 [==============================] - 0s 24ms/step - loss: 9.3320e-08 - accuracy: 1.0000 - val_loss: 6.6892 - val_accuracy: 0.3333\n","Epoch 120/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.0398e-07 - accuracy: 1.0000 - val_loss: 6.6960 - val_accuracy: 0.3333\n","Epoch 121/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.0022e-07 - accuracy: 1.0000 - val_loss: 6.6994 - val_accuracy: 0.3333\n","Epoch 122/200\n","15/15 [==============================] - 0s 32ms/step - loss: 1.1296e-07 - accuracy: 1.0000 - val_loss: 6.7021 - val_accuracy: 0.3333\n","Epoch 123/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.1156e-07 - accuracy: 1.0000 - val_loss: 6.7049 - val_accuracy: 0.3333\n","Epoch 124/200\n","15/15 [==============================] - 0s 23ms/step - loss: 7.5612e-08 - accuracy: 1.0000 - val_loss: 6.7107 - val_accuracy: 0.3333\n","Epoch 125/200\n","15/15 [==============================] - 0s 23ms/step - loss: 9.1006e-08 - accuracy: 1.0000 - val_loss: 6.7123 - val_accuracy: 0.3333\n","Epoch 126/200\n","15/15 [==============================] - 0s 23ms/step - loss: 8.8538e-08 - accuracy: 1.0000 - val_loss: 6.7147 - val_accuracy: 0.3333\n","Epoch 127/200\n","15/15 [==============================] - 0s 24ms/step - loss: 6.8216e-08 - accuracy: 1.0000 - val_loss: 6.7208 - val_accuracy: 0.3333\n","Epoch 128/200\n","15/15 [==============================] - 0s 23ms/step - loss: 8.3844e-08 - accuracy: 1.0000 - val_loss: 6.7258 - val_accuracy: 0.3333\n","Epoch 129/200\n","15/15 [==============================] - 0s 23ms/step - loss: 7.9365e-08 - accuracy: 1.0000 - val_loss: 6.7283 - val_accuracy: 0.3333\n","Epoch 130/200\n","15/15 [==============================] - 0s 24ms/step - loss: 8.0753e-08 - accuracy: 1.0000 - val_loss: 6.7319 - val_accuracy: 0.3333\n","Epoch 131/200\n","15/15 [==============================] - 0s 24ms/step - loss: 8.1883e-08 - accuracy: 1.0000 - val_loss: 6.7322 - val_accuracy: 0.3333\n","Epoch 132/200\n","15/15 [==============================] - 0s 23ms/step - loss: 7.2809e-08 - accuracy: 1.0000 - val_loss: 6.7360 - val_accuracy: 0.3333\n","Epoch 133/200\n","15/15 [==============================] - 0s 23ms/step - loss: 8.8369e-08 - accuracy: 1.0000 - val_loss: 6.7369 - val_accuracy: 0.3333\n","Epoch 134/200\n","15/15 [==============================] - 0s 23ms/step - loss: 8.1590e-08 - accuracy: 1.0000 - val_loss: 6.7402 - val_accuracy: 0.3333\n","Epoch 135/200\n","15/15 [==============================] - 0s 24ms/step - loss: 7.2412e-08 - accuracy: 1.0000 - val_loss: 6.7443 - val_accuracy: 0.3333\n","Epoch 136/200\n","15/15 [==============================] - 0s 23ms/step - loss: 9.9217e-08 - accuracy: 1.0000 - val_loss: 6.7461 - val_accuracy: 0.3333\n","Epoch 137/200\n","15/15 [==============================] - 0s 23ms/step - loss: 6.1434e-08 - accuracy: 1.0000 - val_loss: 6.7473 - val_accuracy: 0.3333\n","Epoch 138/200\n","15/15 [==============================] - 0s 23ms/step - loss: 9.5593e-08 - accuracy: 1.0000 - val_loss: 6.7438 - val_accuracy: 0.3333\n","Epoch 139/200\n","15/15 [==============================] - 0s 23ms/step - loss: 7.6031e-08 - accuracy: 1.0000 - val_loss: 6.7482 - val_accuracy: 0.3333\n","Epoch 140/200\n","15/15 [==============================] - 0s 23ms/step - loss: 6.8449e-08 - accuracy: 1.0000 - val_loss: 6.7475 - val_accuracy: 0.3333\n","Epoch 141/200\n","15/15 [==============================] - 0s 23ms/step - loss: 8.2523e-08 - accuracy: 1.0000 - val_loss: 6.7466 - val_accuracy: 0.3333\n","Epoch 142/200\n","15/15 [==============================] - 0s 24ms/step - loss: 5.9819e-08 - accuracy: 1.0000 - val_loss: 6.7475 - val_accuracy: 0.3333\n","Epoch 143/200\n","15/15 [==============================] - 0s 23ms/step - loss: 6.7815e-08 - accuracy: 1.0000 - val_loss: 6.7495 - val_accuracy: 0.3333\n","Epoch 144/200\n","15/15 [==============================] - 0s 24ms/step - loss: 8.3233e-08 - accuracy: 1.0000 - val_loss: 6.7510 - val_accuracy: 0.3333\n","Epoch 145/200\n","15/15 [==============================] - 0s 24ms/step - loss: 6.0836e-08 - accuracy: 1.0000 - val_loss: 6.7512 - val_accuracy: 0.3333\n","Epoch 146/200\n","15/15 [==============================] - 0s 24ms/step - loss: 6.3931e-08 - accuracy: 1.0000 - val_loss: 6.7524 - val_accuracy: 0.3333\n","Epoch 147/200\n","15/15 [==============================] - 0s 24ms/step - loss: 3.9636e-08 - accuracy: 1.0000 - val_loss: 6.7513 - val_accuracy: 0.3333\n","Epoch 148/200\n","15/15 [==============================] - 0s 23ms/step - loss: 6.9623e-08 - accuracy: 1.0000 - val_loss: 6.7522 - val_accuracy: 0.3333\n","Epoch 149/200\n","15/15 [==============================] - 0s 23ms/step - loss: 5.0766e-08 - accuracy: 1.0000 - val_loss: 6.7519 - val_accuracy: 0.3333\n","Epoch 150/200\n","15/15 [==============================] - 0s 24ms/step - loss: 7.5865e-08 - accuracy: 1.0000 - val_loss: 6.7491 - val_accuracy: 0.3333\n","Epoch 151/200\n","15/15 [==============================] - 0s 23ms/step - loss: 4.6715e-08 - accuracy: 1.0000 - val_loss: 6.7500 - val_accuracy: 0.3333\n","Epoch 152/200\n","15/15 [==============================] - 0s 24ms/step - loss: 6.0732e-08 - accuracy: 1.0000 - val_loss: 6.7534 - val_accuracy: 0.3333\n","Epoch 153/200\n","15/15 [==============================] - 0s 25ms/step - loss: 4.9366e-08 - accuracy: 1.0000 - val_loss: 6.7552 - val_accuracy: 0.3333\n","Epoch 154/200\n","15/15 [==============================] - 0s 24ms/step - loss: 6.0534e-08 - accuracy: 1.0000 - val_loss: 6.7585 - val_accuracy: 0.3333\n","Epoch 155/200\n","15/15 [==============================] - 0s 23ms/step - loss: 4.6219e-08 - accuracy: 1.0000 - val_loss: 6.7590 - val_accuracy: 0.3333\n","Epoch 156/200\n","15/15 [==============================] - 0s 24ms/step - loss: 4.5751e-08 - accuracy: 1.0000 - val_loss: 6.7610 - val_accuracy: 0.3333\n","Epoch 157/200\n","15/15 [==============================] - 0s 23ms/step - loss: 5.5823e-08 - accuracy: 1.0000 - val_loss: 6.7608 - val_accuracy: 0.3333\n","Epoch 158/200\n","15/15 [==============================] - 0s 24ms/step - loss: 6.0797e-08 - accuracy: 1.0000 - val_loss: 6.7627 - val_accuracy: 0.3333\n","Epoch 159/200\n","15/15 [==============================] - 0s 23ms/step - loss: 6.9027e-08 - accuracy: 1.0000 - val_loss: 6.7628 - val_accuracy: 0.3333\n","Epoch 160/200\n","15/15 [==============================] - 0s 24ms/step - loss: 3.6778e-08 - accuracy: 1.0000 - val_loss: 6.7668 - val_accuracy: 0.3333\n","Epoch 161/200\n","15/15 [==============================] - 0s 23ms/step - loss: 5.0185e-08 - accuracy: 1.0000 - val_loss: 6.7669 - val_accuracy: 0.3333\n","Epoch 162/200\n","15/15 [==============================] - 0s 22ms/step - loss: 5.1515e-08 - accuracy: 1.0000 - val_loss: 6.7707 - val_accuracy: 0.3333\n","Epoch 163/200\n","15/15 [==============================] - 0s 23ms/step - loss: 4.8714e-08 - accuracy: 1.0000 - val_loss: 6.7751 - val_accuracy: 0.3333\n","Epoch 164/200\n","15/15 [==============================] - 0s 23ms/step - loss: 5.9711e-08 - accuracy: 1.0000 - val_loss: 6.7776 - val_accuracy: 0.3333\n","Epoch 165/200\n","15/15 [==============================] - 0s 24ms/step - loss: 3.2470e-08 - accuracy: 1.0000 - val_loss: 6.7804 - val_accuracy: 0.3333\n","Epoch 166/200\n","15/15 [==============================] - 0s 24ms/step - loss: 3.1575e-08 - accuracy: 1.0000 - val_loss: 6.7847 - val_accuracy: 0.3333\n","Epoch 167/200\n","15/15 [==============================] - 0s 23ms/step - loss: 4.7280e-08 - accuracy: 1.0000 - val_loss: 6.7896 - val_accuracy: 0.3333\n","Epoch 168/200\n","15/15 [==============================] - 0s 23ms/step - loss: 3.8289e-08 - accuracy: 1.0000 - val_loss: 6.7951 - val_accuracy: 0.3333\n","Epoch 169/200\n","15/15 [==============================] - 0s 24ms/step - loss: 2.5581e-08 - accuracy: 1.0000 - val_loss: 6.7991 - val_accuracy: 0.3333\n","Epoch 170/200\n","15/15 [==============================] - 0s 32ms/step - loss: 5.1022e-08 - accuracy: 1.0000 - val_loss: 6.8025 - val_accuracy: 0.3333\n","Epoch 171/200\n","15/15 [==============================] - 0s 23ms/step - loss: 3.7593e-08 - accuracy: 1.0000 - val_loss: 6.8070 - val_accuracy: 0.3333\n","Epoch 172/200\n","15/15 [==============================] - 0s 23ms/step - loss: 3.1909e-08 - accuracy: 1.0000 - val_loss: 6.8107 - val_accuracy: 0.3333\n","Epoch 173/200\n","15/15 [==============================] - 0s 24ms/step - loss: 3.4352e-08 - accuracy: 1.0000 - val_loss: 6.8156 - val_accuracy: 0.3333\n","Epoch 174/200\n","15/15 [==============================] - 0s 25ms/step - loss: 3.6369e-08 - accuracy: 1.0000 - val_loss: 6.8188 - val_accuracy: 0.3333\n","Epoch 175/200\n","15/15 [==============================] - 0s 23ms/step - loss: 2.2905e-08 - accuracy: 1.0000 - val_loss: 6.8234 - val_accuracy: 0.3333\n","Epoch 176/200\n","15/15 [==============================] - 0s 24ms/step - loss: 3.7793e-08 - accuracy: 1.0000 - val_loss: 6.8264 - val_accuracy: 0.3333\n","Epoch 177/200\n","15/15 [==============================] - 0s 24ms/step - loss: 3.3168e-08 - accuracy: 1.0000 - val_loss: 6.8294 - val_accuracy: 0.3333\n","Epoch 178/200\n","15/15 [==============================] - 0s 23ms/step - loss: 2.2935e-08 - accuracy: 1.0000 - val_loss: 6.8323 - val_accuracy: 0.3333\n","Epoch 179/200\n","15/15 [==============================] - 0s 24ms/step - loss: 2.6955e-08 - accuracy: 1.0000 - val_loss: 6.8371 - val_accuracy: 0.3333\n","Epoch 180/200\n","15/15 [==============================] - 0s 24ms/step - loss: 3.4396e-08 - accuracy: 1.0000 - val_loss: 6.8394 - val_accuracy: 0.3333\n","Epoch 181/200\n","15/15 [==============================] - 0s 24ms/step - loss: 3.5071e-08 - accuracy: 1.0000 - val_loss: 6.8429 - val_accuracy: 0.3333\n","Epoch 182/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.6179e-08 - accuracy: 1.0000 - val_loss: 6.8451 - val_accuracy: 0.3333\n","Epoch 183/200\n","15/15 [==============================] - 0s 24ms/step - loss: 2.4908e-08 - accuracy: 1.0000 - val_loss: 6.8476 - val_accuracy: 0.3333\n","Epoch 184/200\n","15/15 [==============================] - 0s 23ms/step - loss: 2.9474e-08 - accuracy: 1.0000 - val_loss: 6.8501 - val_accuracy: 0.3333\n","Epoch 185/200\n","15/15 [==============================] - 0s 24ms/step - loss: 2.1696e-08 - accuracy: 1.0000 - val_loss: 6.8556 - val_accuracy: 0.3333\n","Epoch 186/200\n","15/15 [==============================] - 0s 24ms/step - loss: 2.7868e-08 - accuracy: 1.0000 - val_loss: 6.8572 - val_accuracy: 0.3333\n","Epoch 187/200\n","15/15 [==============================] - 0s 24ms/step - loss: 3.2633e-08 - accuracy: 1.0000 - val_loss: 6.8625 - val_accuracy: 0.3333\n","Epoch 188/200\n","15/15 [==============================] - 0s 23ms/step - loss: 2.5222e-08 - accuracy: 1.0000 - val_loss: 6.8653 - val_accuracy: 0.3333\n","Epoch 189/200\n","15/15 [==============================] - 0s 24ms/step - loss: 2.9292e-08 - accuracy: 1.0000 - val_loss: 6.8689 - val_accuracy: 0.3333\n","Epoch 190/200\n","15/15 [==============================] - 0s 23ms/step - loss: 2.8997e-08 - accuracy: 1.0000 - val_loss: 6.8694 - val_accuracy: 0.3333\n","Epoch 191/200\n","15/15 [==============================] - 0s 23ms/step - loss: 4.1425e-08 - accuracy: 1.0000 - val_loss: 6.8718 - val_accuracy: 0.3333\n","Epoch 192/200\n","15/15 [==============================] - 0s 24ms/step - loss: 2.1423e-08 - accuracy: 1.0000 - val_loss: 6.8752 - val_accuracy: 0.3333\n","Epoch 193/200\n","15/15 [==============================] - 0s 23ms/step - loss: 3.3419e-08 - accuracy: 1.0000 - val_loss: 6.8761 - val_accuracy: 0.3333\n","Epoch 194/200\n","15/15 [==============================] - 0s 23ms/step - loss: 2.3778e-08 - accuracy: 1.0000 - val_loss: 6.8807 - val_accuracy: 0.3333\n","Epoch 195/200\n","15/15 [==============================] - 0s 23ms/step - loss: 2.6604e-08 - accuracy: 1.0000 - val_loss: 6.8818 - val_accuracy: 0.3333\n","Epoch 196/200\n","15/15 [==============================] - 0s 23ms/step - loss: 2.8053e-08 - accuracy: 1.0000 - val_loss: 6.8833 - val_accuracy: 0.3333\n","Epoch 197/200\n","15/15 [==============================] - 0s 23ms/step - loss: 2.9075e-08 - accuracy: 1.0000 - val_loss: 6.8865 - val_accuracy: 0.3333\n","Epoch 198/200\n","15/15 [==============================] - 0s 23ms/step - loss: 3.0317e-08 - accuracy: 1.0000 - val_loss: 6.8888 - val_accuracy: 0.3333\n","Epoch 199/200\n","15/15 [==============================] - 0s 23ms/step - loss: 1.6060e-08 - accuracy: 1.0000 - val_loss: 6.8897 - val_accuracy: 0.3333\n","Epoch 200/200\n","15/15 [==============================] - 0s 24ms/step - loss: 2.4270e-08 - accuracy: 1.0000 - val_loss: 6.8922 - val_accuracy: 0.3333\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f2edb997630>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"iUHBAgQ2hZ4H"},"source":["### 모델평가하기"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OIe9kFWdhaCc","executionInfo":{"status":"ok","timestamp":1613524552313,"user_tz":-540,"elapsed":754,"user":{"displayName":"고녹녹","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1UXxlJ9dgM27f3BTzP91L9Si-FkCyJfTt58oI=s64","userId":"12157940257772241278"}},"outputId":"d110ba0d-3aea-404d-8486-5f6548da7f39"},"source":["print(\"-- Evaluate --\")\r\n","scores = model.evaluate_generator(test_generator, steps=5) #추가됨 _generator\r\n","print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\r\n","#33.33% 이래서 DataAumentation을 해야하는 이유 ㅋ.ㅋ"],"execution_count":14,"outputs":[{"output_type":"stream","text":["-- Evaluate --\n","accuracy: 33.33%\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n","  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"HqciKc9bhaEs"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mnAROyqahaHE"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DOhWVix1haJd"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Kaf1_fehaL_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MOq0ej5ihaOV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QgQv-NNshaQ3"},"source":[""],"execution_count":null,"outputs":[]}]}